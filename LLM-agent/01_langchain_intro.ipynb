{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91311315",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "`01_langchain_intro.ipynb`\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97edc2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42b19cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc48c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CBB2BMUtdgF2hUXkMs3UavxXvkbWg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--78a19bca-8b5f-431f-ae00-c577cff88531-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19087e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면 한국어로 번역을 해주는 AI 를 만들고 싶다면?\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4572d386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Andiamo a pranzo. Cosa sarebbe meglio mangiare?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 39, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CAsCow7x1tkbx5MNtHTNB6T07KGJF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bd6caae5-0b37-4cd0-8225-98a12986b073-0', usage_metadata={'input_tokens': 39, 'output_tokens': 13, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='한국어를 이탈리어로 번역해줘'),\n",
    "    HumanMessage(content='점심을 먹자. 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5099c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sono sazio.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 27, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CArff1azzxlgcoa7iiYl6XTHtZoMQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ed9cff37-4559-4747-8879-a8506012636f-0', usage_metadata={'input_tokens': 27, 'output_tokens': 4, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': '한국어를 이탈리어로 번역해줘'},\n",
    "    {'role': 'human', 'content': '배부르다'},\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea4f8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|A|vere| fame||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd2a0e",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법 \n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(LCEL-LanChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01205265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司が食べたいです', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 24, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArfkBqfHSrh917YmeH5rbbbfrQMr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--48b3981f-902b-4f9d-b53b-c5297c0052cf-0', usage_metadata={'input_tokens': 24, 'output_tokens': 7, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10604f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 22, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArfmoTYs25aFkZZwoDT8ZFLq4dnN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1656a7c9-46d5-49e1-8251-be77f7256415-0', usage_metadata={'input_tokens': 22, 'output_tokens': 7, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "454b287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# a | b | c => \n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d3b79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 전반기(1월~6월) 매출 분석을 위한 데이터 분석(EDA) 단계를 아래와 같이 나누어 드리겠습니다:\n",
      "\n",
      "1. 데이터 수집 및 준비\n",
      "   - 매출 데이터, 고객 정보, 상품 정보 등 관련 데이터 수집\n",
      "   - 데이터 파일 형식 확인 (Excel, CSV, 데이터베이스 등)\n",
      "2. 데이터 전처리\n",
      "   - 결측치 및 이상치 확인 및 처리\n",
      "   - 데이터 타입 및 형식 통일\n",
      "   - 필요시 데이터 병합 (예: 고객 정보와 매출 데이터 결합)\n",
      "3. 데이터 탐색적 분석 (EDA)\n",
      "   - 전체 매출 추이 파악: 월별, 분기별 매출 데이터 시각화 (라인 차트, 막대 차트)\n",
      "   - 카테고리별/상품별 매출 분석\n",
      "   - 고객 세그먼트별 매출 분석\n",
      "   - 지역별 매출 분포 분석\n",
      "   - 평균, 중앙값, 표준편차 등의 기초 통계량 계산\n",
      "4. 시간 기반 분석\n",
      "   - 월별/분기별 매출 증가/감소 패턴 분석\n",
      "   - 주요 매출 시기(피크 시즌) 파악\n",
      "5. 이상치 및 특이점 발견\n",
      "   - 비정상적 매출 급등 또는 급감 구간 식별\n",
      "   - 이벤트 또는 프로모션 효과 분석 가능성 검토\n",
      "6. 인사이트 도출 및 요약\n",
      "   - 핵심 매출 동향 및 패턴 정리\n",
      "   - 잠재적 기회 및 문제점 도출\n",
      "7. 시각화 및 보고서 작성\n",
      "   - 이해하기 쉬운 차트 및 그래프 제작\n",
      "   - 분석 결과를 바탕으로 한 인포그래픽 또는 보고서 작성\n",
      "\n",
      "이러한 단계별 분석 계획을 따르면 2025년 전반기 매출 현황을 체계적으로 파악할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가 입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb22c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다. \"2025년 전반기 매출 분석\"을 위한 EDA(탐색적 데이터 분석) 단계를 아래와 같이 나눌 수 있습니다:\n",
      "\n",
      "1. 데이터 수집 및 확인\n",
      "   - 매출 관련 데이터 수집(시계열 데이터, 상품별, 지역별 등)\n",
      "   - 데이터의 형식과 구조 확인(컬럼명, 데이터 타입, 결측치 여부)\n",
      "\n",
      "2. 데이터 정제 및 전처리\n",
      "   - 결측치 처리(제거 또는 대체)\n",
      "   - 이상치 탐지 및 처리\n",
      "   - 날짜 형식 일관성 확보\n",
      "   - 필요한 경우 파생 변수 생성(예: 월별, 분기별, 반기)\n",
      "\n",
      "3. 기초 통계 및 분포 분석\n",
      "   - 전체 매출의 기본 통계량(평균, 중앙값, 표준편차 등)\n",
      "   - 매출 분포 및 히스토그램, 박스플롯 시각화\n",
      "   - 상품군별/지역별 매출 분포 분석\n",
      "\n",
      "4. 시계열 분석\n",
      "   - 월별 또는 분기별 매출 trend 파악\n",
      "   - 계절성 여부 확인\n",
      "   - 성장 또는 감소 추세 분석\n",
      "\n",
      "5. 세그먼트별 분석\n",
      "   - 고객/상품/지역별 매출 기여도 분석\n",
      "   - 규모별, 유형별 세그먼트별 매출 특징 파악\n",
      "\n",
      "6. 상관관계 및 영향 변수 분석\n",
      "   - 매출과 관련된 변수간 상관관계 분석\n",
      "   - 영향 요인 파악 (광고비, 프로모션, 이벤트 등)\n",
      "\n",
      "7. 시각화 작업\n",
      "   - 시계열 차트, 막대그래프, 히트맵 등 활용\n",
      "   - 인사이트 도출을 위한 직관적 시각화 제공\n",
      "\n",
      "8. 인사이트 정리 및 전망\n",
      "   - 주요 발견점 요약\n",
      "   - 향후 전략 수립에 활용 가능한 인사이트 도출\n",
      "\n",
      "이 단계별 분석을 통해 2025년 전반기 매출 현황을 파악하고, 향후 전략 수립에 도움을 줄 수 있습니다."
     ]
    }
   ],
   "source": [
    "# Chain은 Runnable 객체이기 때문에 invoke, stream, batch 에서도 사용가능\n",
    "\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dcf9421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어 처리를 위한 오픈소스 프레임워크로, 다양한 언어 모델과 도구들을 쉽게 통합하고 활용할 수 있게 도와줍니다. 이를 통해 개발자는 대화형 에이전트, 텍스트 생성, 질의 응답 시스템 등을 빠르게 구축할 수 있습니다. 또한, 데이터 소스와의 연동 기능도 지원하여 복잡한 자연어 이해 및 처리 작업을 간소화합니다.',\n",
       " 'Langsmith는 개발자들이 자연어 처리 기술을 쉽게 적용할 수 있도록 돕는 플랫폼으로, 코드 작성과 모델 연동을 지원합니다. 사용자 친화적인 인터페이스와 다양한 도구를 통해 챗봇과 AI 애플리케이션을 빠르게 개발할 수 있습니다. 또한, 커스터마이징과 확장이 용이하여 기업이나 개발자가 맞춤형 AI 솔루션을 구축하는 데 적합합니다.',\n",
       " 'Langgraph는 자연어 처리와 그래프 이론을 결합한 기술로, 텍스트 데이터 내의 정보를 그래프로 표현하여 의미 관계를 시각화하고 분석합니다. 이를 통해 복잡한 언어 구조와 연관성을 효율적으로 파악할 수 있으며, 정보 검색이나 지식 추출에 유용하게 활용됩니다. 또한, 머신러닝 기법과 결합하여 더 정교한 언어 이해와 자연어 처리 성능을 향상시키는 데 기여합니다.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'},\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
